{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# LTE Data Science Capstone Project\nDevelop a machine learning model to analyze and predict car accident severity\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "# Get Data\n!wget -O Data-Collisions.csv https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv\n\ndf = pd.read_csv('Data-Collisions.csv')",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "--2020-09-11 14:20:37--  https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv\nResolving s3.us.cloud-object-storage.appdomain.cloud (s3.us.cloud-object-storage.appdomain.cloud)... 67.228.254.196\nConnecting to s3.us.cloud-object-storage.appdomain.cloud (s3.us.cloud-object-storage.appdomain.cloud)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 73917638 (70M) [text/csv]\nSaving to: \u2018Data-Collisions.csv\u2019\n\n100%[======================================>] 73,917,638  47.3MB/s   in 1.5s   \n\n2020-09-11 14:20:39 (47.3 MB/s) - \u2018Data-Collisions.csv\u2019 saved [73917638/73917638]\n\n",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# DOWN sample\nfrom sklearn.utils import resample\n\n# Separate majority and minority classes\ndf_maj = df[df.SEVERITYCODE == 1]\ndf_min = df[df.SEVERITYCODE == 2]\n\n# Down sample minority class\ndf_maj_dnsampled = resample(df_maj, \n                            replace = False,     # sample with replacement\n                            n_samples = 58188)    # to match minority class\n\n# Combine majority class with down sampled  class\ndf_dnsampled = pd.concat([df_min, df_maj_dnsampled])\n \n# Display new class counts\ndf_dnsampled.SEVERITYCODE.value_counts()",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 3,
                    "data": {
                        "text/plain": "2    58188\n1    58188\nName: SEVERITYCODE, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Down Sample 2\nfeature = df_dnsampled[['WEATHER', 'ROADCOND', 'LIGHTCOND']] #.values\ny = df_dnsampled['SEVERITYCODE'].values\n\n\ncleanup_nums = {'WEATHER': {\"Clear\": 11, 'Raining': 1, 'Overcast': 2, 'Unknown': 3,\n                              'Snowing': 4, 'Other': 5, 'Fog/Smog/Smoke': 6, 'Sleet/Hail/Freezing Rain': 7,\n                              'Blowing Sand/Dirt': 8, 'Severe Crosswind': 9, 'Partly Cloudy': 10},\n                'ROADCOND': {\"Dry\": 11, \"Wet\": 1, \"Unknown\": 2, \"Ice\": 3,\n                              \"Snow/Slush\": 4, \"Other\": 5, \"Standing Water\": 6,\n                              'Sand/Mud/Dirt': 7, 'Oil': 8},\n               'LIGHTCOND': {'Daylight': 11, 'Dark - Street Lights On': 1, 'Unknown': 2, 'Dusk': 3, \n                            'Dawn': 4, 'Dark - No Street Lights': 5, 'Dark - Street Lights Off': 6,\n                            'Other': 7, 'Dark - Unknown Lighting':8}}\n\nfeature.replace(cleanup_nums, inplace=True)\n\nX = feature",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/generic.py:6517: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  regex=regex)\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Category Transformation: Find/Replace"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X.replace(np.nan,11, inplace=True)",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/frame.py:4042: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  method=method)\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "array([[-1.18965992, -1.50762022,  0.7419481 ],\n       [-1.41028904, -1.50762022,  0.7419481 ],\n       [ 0.79600218,  0.68776244,  0.7419481 ],\n       [ 0.79600218,  0.68776244,  0.7419481 ],\n       [ 0.79600218,  0.68776244, -1.45202053]])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train set: (81463, 3) (81463,)\nTest set: (34913, 3) (34913,)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# K Nearest Neighbor"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nKs = 20\nmean_acc = np.zeros((Ks-1))\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train, y_train)\n    yhat = neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\nprint(\"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "The best accuracy was with 0.5564975796981068 with k= 17\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "neigh = KNeighborsClassifier(n_neighbors = 17).fit(X_train,y_train)\nneigh",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 19,
                    "data": {
                        "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=17, p=2,\n           weights='uniform')"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\n\n#KNN Calculations\nyhat_knn = neigh.predict(X_test)\n\n# jaccard\njaccard_knn = jaccard_similarity_score(y_test, yhat_knn)\nprint(\"KNN Jaccard index: \", jaccard_knn)\n\n# f1_score\nf1_score_knn = f1_score(y_test, yhat_knn, average='weighted')\nprint(\"KNN F1-score: \", f1_score_knn)",
            "execution_count": 22,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "KNN Jaccard index:  0.5564975796981068\nKNN F1-score:  0.5313474488839894\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Decision Tree"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.tree import DecisionTreeClassifier\n\nTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nTree.fit(X_train,y_train)\nyhatTree = Tree.predict(X_test)\n\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, yhatTree))",
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "DecisionTrees's Accuracy:  0.5571277174691376\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Decision Tree Calculations\nyhat_dt = Tree.predict(X_test)\n\n# jaccard\njaccard_dt = jaccard_similarity_score(y_test, yhat_dt)\nprint(\"DT Jaccard index: \", jaccard_dt)\n\n# f1_score\nf1_score_dt = f1_score(y_test, yhat_dt, average='weighted')\nprint(\"DT F1-score: \", f1_score_dt)",
            "execution_count": 24,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "DT Jaccard index:  0.5571277174691376\nDT F1-score:  0.5217561355391311\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Logistic Regression"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)",
            "execution_count": 25,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Logistic Regression Calculations\nyhat_lg = LR.predict(X_test)\nyhat_lg_prob = LR.predict_proba(X_test)\n\n# jaccard\njaccard_lg = jaccard_similarity_score(y_test, yhat_lg)\nprint(\"LR Jaccard index: \", jaccard_lg)\n\n# f1_score\nf1_score_lg = f1_score(y_test, yhat_lg, average='weighted')\nprint(\"LR F1-score: \", f1_score_lg)",
            "execution_count": 26,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "LR Jaccard index:  0.5407727780482915\nLR F1-score:  0.5334004908537546\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Report"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "| Algorithm          | Jaccard | F1-score | \n|--------------------|---------|----------|\n| KNN                | 0.55649  | 0.53134        | \n| Decision Tree      | 0.55712       | 0.52175        | \n| LogisticRegression | 0.54077       | 0.5334       | "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "##### On the basis the KNN method had a higher F1 score and only slightly lower Jaccard score compared to the Decision Tree, it is recommended the KNN method be used to determine accident severity."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}